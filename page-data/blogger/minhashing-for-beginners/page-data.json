{"componentChunkName":"component---src-templates-blog-post-js","path":"/blogger/minhashing-for-beginners/","result":{"data":{"site":{"siteMetadata":{"title":"Coding with Thomas"}},"markdownRemark":{"id":"20c92f62-8d52-566b-8cff-74a7b830a248","excerpt":"Due to popular demand of my MinHashing class in my common library, I decided to do a quick and dirty walkthrough of how to vectorize, MinHash and lookup your…","html":"<p>Due to popular demand of my MinHashing class in my common library, I decided to do a quick and dirty walkthrough of how to vectorize, MinHash and lookup your data!</p>\n<p><strong>What is MinHashing good for?</strong><br>\nMinHashing in the first place is used to speed up nearest neighbour lookups. Think of having this huge terabyte sized dataset of movie reviews and you want to find similar reviews (either for deduplication or for recommendation).</p>\n<p>Now MinHashing will give you a very small and dense representation of your data by hashing values of a vectorized representation of your data. <a href=\"http://en.wikipedia.org/wiki/MinHash\">You can read more about the theory and some details behind it on Wikipedia.</a></p>\n<p><strong>Example Data</strong></p>\n<p>To get some base-line data, let’s grab a dataset from Kaggle. <a href=\"http://www.kaggle.com/c/word2vec-nlp-tutorial/data\">This example uses the 50k movie reviews from IMDB</a>, namely the “unlabeledTrainData.tsv”. Sign-in and get the data from there- alternatively any data will do if it has the same columnar TSV style formatting, here is an example:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">id review  \n\"9999\\_0\" \"Watching Time Chasers, it obvious that it was made by a bunch of friends. Maybe they were sitting around one day in film school and said, \\\\\"Hey, let's pool our money together and make a really bad movie!\\\\\" Or something like that. What ever they said, they still ended up making a really bad movie--dull story, bad script, lame acting, poor cinematography, bottom of the barrel stock music, etc. All corners were cut, except the one that would have prevented this film's release. Life's like that.\"  \n\"45057\\_0\" \"I saw this film about 20 years ago and remember it as being particularly nasty. I believe it is based on a true incident: a young man breaks into a nurses' home and rapes, tortures and kills various women.&lt;br />&lt;br />It is in black and white but saves the colour for one shocking shot.&lt;br />&lt;br />At the end the film seems to be trying to make some political statement but it just comes across as confused and obscene.&lt;br />&lt;br />Avoid.\"  \n</code></pre></div>\n<p>We need to do some massaging here, since there are some HTML parts in it, but for this example we can simply get away with lower casing and removing everything that isn’t alphanumeric.</p>\n<p><strong>Tokenization and Vectorization</strong></p>\n<p>The main part here is to normalize and tokenize the data into bigrams that we can use our vectorizer to build TF-IDF or bag-of-word-frequency vectors out of it. Using my common library and Java 8 streams this looks like this:</p>\n<div class=\"gatsby-highlight\" data-language=\"java\"><pre class=\"language-java\"><code class=\"language-java\"><span class=\"token class-name\">Stream</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">String</span><span class=\"token punctuation\">></span></span> lines <span class=\"token operator\">=</span> <span class=\"token class-name\">Files</span><span class=\"token punctuation\">.</span><span class=\"token function\">lines</span><span class=\"token punctuation\">(</span>  \n    <span class=\"token class-name\">Paths</span><span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"unlabeledTrainData.tsv\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  \n    <span class=\"token punctuation\">.</span><span class=\"token function\">skip</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// skip the header  </span>\n  \n<span class=\"token comment\">// normalization and bigram tokenization  </span>\n<span class=\"token class-name\">List</span><span class=\"token operator\">&lt;</span><span class=\"token class-name\">String</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token operator\">></span> documents <span class=\"token operator\">=</span> lines  \n    <span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>line<span class=\"token punctuation\">)</span> <span class=\"token operator\">-></span> <span class=\"token class-name\">TokenizerUtils</span><span class=\"token punctuation\">.</span><span class=\"token function\">normalizeString</span><span class=\"token punctuation\">(</span>line<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  \n    <span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>normalized<span class=\"token punctuation\">)</span> <span class=\"token operator\">-></span> <span class=\"token class-name\">TokenizerUtils</span><span class=\"token punctuation\">.</span><span class=\"token function\">whiteSpaceTokenizeNGrams</span><span class=\"token punctuation\">(</span>normalized<span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  \n    <span class=\"token punctuation\">.</span><span class=\"token function\">collect</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">Collectors</span><span class=\"token punctuation\">.</span><span class=\"token function\">toList</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  \n  \n<span class=\"token comment\">// every token that occurs more often than 50% in the corpus and less than twice will be discarded  </span>\n<span class=\"token class-name\">String</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> dict <span class=\"token operator\">=</span> <span class=\"token class-name\">VectorizerUtils</span><span class=\"token punctuation\">.</span><span class=\"token function\">buildDictionary</span><span class=\"token punctuation\">(</span>documents<span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.5f</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  \n<span class=\"token class-name\">List</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">DoubleVector</span><span class=\"token punctuation\">></span></span> vectors <span class=\"token operator\">=</span> <span class=\"token class-name\">VectorizerUtils</span><span class=\"token punctuation\">.</span><span class=\"token function\">wordFrequencyVectorize</span><span class=\"token punctuation\">(</span>documents<span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">parallel</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dict<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">collect</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">Collectors</span><span class=\"token punctuation\">.</span><span class=\"token function\">toList</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </code></pre></div>\n<p><strong>MinHashing</strong></p>\n<p>Now that we have the vectors, we can MinHash them.</p>\n<div class=\"gatsby-highlight\" data-language=\"java\"><pre class=\"language-java\"><code class=\"language-java\"><span class=\"token class-name\">MinHash</span> hasher <span class=\"token operator\">=</span> <span class=\"token class-name\">MinHash</span><span class=\"token punctuation\">.</span><span class=\"token function\">create</span><span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">HashType</span><span class=\"token punctuation\">.</span><span class=\"token constant\">MURMUR128</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  \n<span class=\"token class-name\">List</span><span class=\"token operator\">&lt;</span><span class=\"token keyword\">int</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token operator\">></span> minHashes <span class=\"token operator\">=</span> vectors<span class=\"token punctuation\">.</span><span class=\"token function\">stream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">)</span> <span class=\"token operator\">-></span> hasher<span class=\"token punctuation\">.</span><span class=\"token function\">minHashVector</span><span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">collect</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">Collectors</span><span class=\"token punctuation\">.</span><span class=\"token function\">toList</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </code></pre></div>\n<p>In this case, we go for 20 minhashes and a rather strong murmur 128 bit hash. This is usually the default I try out for various text tasks.</p>\n<p><strong>Finding Similar Documents</strong></p>\n<p>To find similar documents, we have two ways: brute force or using an inverted index. Let’s start using brute force by finding the top five similar elements to the third (index = 2) movie review in our list.</p>\n<div class=\"gatsby-highlight\" data-language=\"java\"><pre class=\"language-java\"><code class=\"language-java\"><span class=\"token keyword\">final</span> <span class=\"token keyword\">int</span> sourceDocIndex <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">;</span>  \n\n<span class=\"token comment\">// document index  </span>\n<span class=\"token class-name\">LimitedPriorityQueue</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">Integer</span><span class=\"token punctuation\">></span></span> queue <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">LimitedPriorityQueue</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token punctuation\">></span></span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  \n\n<span class=\"token keyword\">int</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> first <span class=\"token operator\">=</span> minHashes<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span>sourceDocIndex<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  \n\n<span class=\"token class-name\">Stopwatch</span> watch <span class=\"token operator\">=</span> <span class=\"token class-name\">Stopwatch</span><span class=\"token punctuation\">.</span><span class=\"token function\">createStarted</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  \n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> minHashes<span class=\"token punctuation\">.</span><span class=\"token function\">size</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>  \n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">!=</span> sourceDocIndex<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>  \n    <span class=\"token keyword\">int</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> reference <span class=\"token operator\">=</span> minHashes<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  \n    <span class=\"token keyword\">double</span> similarity <span class=\"token operator\">=</span> hasher<span class=\"token punctuation\">.</span><span class=\"token function\">measureSimilarity</span><span class=\"token punctuation\">(</span>first<span class=\"token punctuation\">,</span> reference<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  \n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>similarity <span class=\"token operator\">></span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>  \n      queue<span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">,</span> similarity<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  \n    <span class=\"token punctuation\">}</span>  \n  <span class=\"token punctuation\">}</span>  \n<span class=\"token punctuation\">}</span>  \n\n<span class=\"token class-name\">System</span><span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Done finding similar docs in \"</span>  \n    <span class=\"token operator\">+</span> watch<span class=\"token punctuation\">.</span><span class=\"token function\">elapsed</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">TimeUnit</span><span class=\"token punctuation\">.</span><span class=\"token constant\">MILLISECONDS</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token string\">\"ms!\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  \n\n<span class=\"token class-name\">System</span><span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"document:\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  \n<span class=\"token class-name\">System</span><span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>lines<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span>sourceDocIndex<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  \n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>queue<span class=\"token punctuation\">.</span><span class=\"token function\">isEmpty</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>  \n  <span class=\"token keyword\">double</span> similarity <span class=\"token operator\">=</span> queue<span class=\"token punctuation\">.</span><span class=\"token function\">getMaximumPriority</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  \n  <span class=\"token keyword\">int</span> index <span class=\"token operator\">=</span> queue<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  \n  <span class=\"token class-name\">System</span><span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>similarity <span class=\"token operator\">+</span> <span class=\"token string\">\" -> \"</span> <span class=\"token operator\">+</span> lines<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span>index<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  \n<span class=\"token punctuation\">}</span>  </code></pre></div>\n<p>This will output a very interesting pattern:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Done finding similar docs in 146ms!  \ndocument:  \n\"15561_0\" \"Minor Spoilers&lt;br />&lt;br />In New York, Joan Barnard (Elvire Audrey) is informed that her husband, the archeologist Arthur Barnard (John Saxon), was mysteriously murdered in Italy while searching an Etruscan tomb. Joan decides to travel to Italy, in the company of her colleague, who offers his support. Once in Italy, she starts having visions relative to an ancient people and maggots, many maggots. After shootings and weird events, Joan realizes that her father is an international drug dealer, there are drugs hidden in the tomb and her colleague is a detective of the narcotic department. The story ends back in New York, when Joan and her colleague decide to get married with each other, in a very romantic end. Yesterday I had the displeasure of wasting my time watching this crap. The story is so absurd, mixing thriller, crime, supernatural and horror (and even a romantic end) in a non-sense way. The acting is the worst possible, highlighting the horrible performance of the beautiful Elvire Audrey. John Saxon just gives his name to the credits and works less than five minutes, when his character is killed. The special effects are limited to maggots everywhere. The direction is ridiculous. I lost a couple of hours of my life watching 'Assassinio al Cimitero Etrusco'. If you have the desire or curiosity of seeing this trash, choose another movie, go to a pizzeria, watch TV, go sleep, navigate in Internet, go to the gym, but do not waste your time like I did. My vote is two.&lt;br />&lt;br />Title (Brazil): 'O Mistério Etrusco' ('The Etruscan Mystery')\"  \n0.9047619047619048 -> \"15556_0\" \"Minor Spoilers&lt;br />&lt;br />In New York, Joan Barnard (Elvire Audrey) is informed that her husband, the archaeologist Arthur Barnard (John Saxon), was mysteriously murdered in Italy while searching an Etruscan tomb. Joan decides to travel to Italy, in the company of her colleague, who offers his support. Once in Italy, she starts having visions relative to an ancient people and maggots, many maggots. After shootings and weird events, Joan realizes that her father is an international drug dealer, there are drugs hidden in the tomb and her colleague is a detective of the narcotic department. The story ends back in New York, when Joan and her colleague decide to get married with each other, in a very romantic end. Yesterday I had the displeasure of wasting my time watching this crap. The story is so absurd, mixing thriller, crime, supernatural and horror (and even a romantic end) in a non-sense way. The acting is the worst possible, highlighting the horrible and screaming performance of the beautiful Elvire Audrey. John Saxon just gives his name to the credits and works less than five minutes, when his character is killed. The special effects are limited to maggots everywhere. The direction is ridiculous. I lost a couple of hours of my life watching 'Assassinio al Cimitero Etrusco'. My suggestion is that if you have the desire or curiosity of seeing this trash, choose another movie, go to a pizzeria, watch TV, go sleep, navigate in Internet, go to the gym, but do not waste your time like I did. My vote is two.&lt;br />&lt;br />Title (Brazil): 'O Mistério Etrusco' ('The Etruscan Mystery')\"  \n0.9047619047619048 -> \"15555_0\" \"Minor Spoilers&lt;br />&lt;br />In New York, Joan Barnard (Elvire Audrey) is informed that her husband, the archeologist Arthur Barnard (John Saxon), was mysteriously murdered in Italy while searching an Etruscan tomb. Joan decides to travel to Italy, in the company of her colleague, who offers his support. Once in Italy, she starts having visions relative to an ancient people and maggots, many maggots. After shootings and weird events, Joan realizes that her father is an international drug dealer, there are drugs hidden in the tomb and her colleague is a detective of the narcotic department. The story ends back in New York, when Joan and her colleague decide to get married with each other, in a very romantic end. Yesterday I had the displeasure of wasting my time watching this crap. The story is so absurd, mixing thriller, crime, supernatural and horror (and even a romantic end) in a non-sense way. The acting is the worst possible, highlighting the horrible and screaming performance of the beautiful Elvire Audrey. John Saxon just gives his name to the credits and works less than five minutes, when his character is killed. The special effects are limited to maggots everywhere. The direction is ridiculous. I lost a couple of hours of my life watching 'Assassinio al Cimitero Etrusco'. If you have the desire or curiosity of seeing this trash, choose another movie, go to a pizzeria, watch TV, go sleep, navigate in Internet, go to the gym, but do not waste your time like I did. AVOID IT! My vote is two.&lt;br />&lt;br />Title (Brazil): 'O Mistério Etrusco' ('The Etruscan Mystery')\"  </code></pre></div>\n<p>It found two near duplicates to the source document we provided!</p>\n<p>Please find the full code <a href=\"https://gist.github.com/thomasjungblut/e4759797f5a52d78e06d\">as a gist here.</a></p>\n<p>Thanks for reading,<br>\nThomas</p>","frontmatter":{"title":"MinHashing for Beginners","date":"5th March 2015","description":null},"tableOfContents":"","timeToRead":6},"previous":{"fields":{"slug":"/blogger/stochastic-logistic-regression-in-f/"},"frontmatter":{"title":"Stochastic Logistic Regression in F#"}},"next":{"fields":{"slug":"/blogger/xgboost-validation-and-early-stopping/"},"frontmatter":{"title":"XGBoost Validation and Early Stopping in R"}}},"pageContext":{"id":"20c92f62-8d52-566b-8cff-74a7b830a248","previousPostId":"21a9784d-ad71-5215-a660-37236303f25c","nextPostId":"542cb632-6a73-5f6c-97fd-9da2eaacba19"}},"staticQueryHashes":["2270107033","2841359383"],"slicesMap":{}}