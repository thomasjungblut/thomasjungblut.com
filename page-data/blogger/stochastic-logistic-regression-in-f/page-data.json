{"componentChunkName":"component---src-templates-blog-post-js","path":"/blogger/stochastic-logistic-regression-in-f/","result":{"data":{"site":{"siteMetadata":{"title":"Coding with Thomas"}},"markdownRemark":{"id":"21a9784d-ad71-5215-a660-37236303f25c","excerpt":"Hello! I’m back with some exiting new hacking. At the beginning of the week, Jon Harrop came to the Microsoft London office and gave a two day training on F…","html":"<p>Hello!</p>\n<p>I’m back with some exiting new hacking. At the beginning of the week, <a href=\"http://www.ffconsultancy.com/\">Jon Harrop</a> came to the Microsoft London office and gave a two day training on F#. The training was nice, I enjoyed it very much and we all laughed a lot.</p>\n<p>In the end, I want to share a small project that I came up with during the training. It is about Stochastic Logistic Regression, or Logistic Regression “learning” the weights using Stochastic Gradient Descent.<br>\nThis is just a small write-up of what I’ve learned, explaining some of the language features.</p>\n<h4 id=\"learning-rule\" style=\"position:relative;\"><a href=\"#learning-rule\" aria-label=\"learning rule permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Learning Rule</h4>\n<p>In (more or less) mathematical terms, we will execute the following algorithm:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Let n = number of iterations  \nLet a = learning rate  \nLet w = weights that need to be learned (including a bias term)  \nFor i to N:  \n  Let f = get a random feature  \n  Let c = the class of feature (either 0 or 1)  \n  Let prediction = Sigmoid ( f dot w )  \n  Let loss = prediction - c  \n    \n  w := w - a \\* f \\* loss  </code></pre></div>\n<p>It is a pretty easy algorithm, can be rewritten to use a convergence criteria very easily since there is only a single global minimum. If you participated in the ML course of Andrew Ng you’ll recognize some similarity, because the full-batch algorithm they used basically uses the whole feature matrix and then updates the gradient by the average over all losses.</p>\n<p>Let’s jump into F#.</p>\n<h4 id=\"training-in-f\" style=\"position:relative;\"><a href=\"#training-in-f\" aria-label=\"training in f permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Training in F#</h4>\n<p>Since we are basically executing a math equation over and over again, it is handy to have a math library at hand. I’ve chosen <a href=\"http://numerics.mathdotnet.com/\">Math.Net Numerics</a>, because it has some nice F# bindings. Let’s start by looking at the training loop of the whole program:</p>\n<div class=\"gatsby-highlight\" data-language=\"fsharp\"><pre class=\"language-fsharp\"><code class=\"language-fsharp\"><span class=\"token keyword\">let</span> <span class=\"token function\">Train</span><span class=\"token punctuation\">(</span>numIterations<span class=\"token punctuation\">,</span> dim<span class=\"token punctuation\">,</span> learningRate<span class=\"token punctuation\">,</span> rnd<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span>   \n    <span class=\"token comment\">// new vector including the bias  </span>\n    <span class=\"token keyword\">let</span> <span class=\"token keyword\">mutable</span> start <span class=\"token operator\">=</span> DenseVector<span class=\"token punctuation\">.</span><span class=\"token function\">CreateRandom</span><span class=\"token punctuation\">(</span>dim <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token function\">Normal</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  \n    <span class=\"token keyword\">for</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span> <span class=\"token keyword\">to</span> numIterations <span class=\"token keyword\">do</span>  \n        <span class=\"token keyword\">let</span> feature <span class=\"token operator\">=</span> <span class=\"token function\">SampleNewFeature</span><span class=\"token punctuation\">(</span>dim<span class=\"token punctuation\">,</span> rnd<span class=\"token punctuation\">)</span>  \n        start <span class=\"token operator\">&lt;-</span> OnlineLogisticRegression<span class=\"token punctuation\">.</span><span class=\"token function\">GradientDescentStep</span><span class=\"token punctuation\">(</span>learningRate<span class=\"token punctuation\">,</span> start<span class=\"token punctuation\">,</span> <span class=\"token function\">FeatureVector</span><span class=\"token punctuation\">(</span>feature<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token function\">FeatureClass</span><span class=\"token punctuation\">(</span>feature<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  \n\n    Console<span class=\"token punctuation\">.</span><span class=\"token function\">WriteLine</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Learned Weights: {0}\"</span><span class=\"token punctuation\">,</span> System<span class=\"token punctuation\">.</span>String<span class=\"token punctuation\">.</span><span class=\"token function\">Join</span><span class=\"token punctuation\">(</span><span class=\"token string\">\", \"</span><span class=\"token punctuation\">,</span> start<span class=\"token punctuation\">.</span><span class=\"token function\">ToArray</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  \n    start</code></pre></div>\n<p>As you can see, F# is pretty much like the (more or less) mathematical notation I used in the previous section. Notable in the first place is that F# is indentation sensitive, just like Python.</p>\n<p>In the first line we define the function ”<em>Train</em>”, which defines some arguments and no return type. F# is quite smart about type inference, so it can detect what the types of the parameters are, so with the return type. In this method, we return the learned weights ”<em>start</em>”- thus the compiler knows that this method returns a <em>DenseVector</em>. Like in most of the functional languages, there is always a return- in case there is not, there is a ”<em>unit</em>” return (literally defined by () ), which always indicates an absense of a value.</p>\n<p>In the raw algorithm, where I used a for loop to loop over all iteration, we sample a new feature and pass it to another function which I defined in the <em>module</em> ”<em>OnlineLogisticRegression</em>” containing the update and calculation logic. At the end, we simply print (using the standard printing in C#) the vector and return it to the outside. You can seamlessly use F# and C# with each other in a program as they compile to the same IL.</p>\n<p>Let’s step into the gradient descent function for a while:</p>\n<div class=\"gatsby-highlight\" data-language=\"fsharp\"><pre class=\"language-fsharp\"><code class=\"language-fsharp\"><span class=\"token comment\">/// Does a stochastic gradient descent step. Returns a new vector with the updated weights.  </span>\n<span class=\"token keyword\">let</span> <span class=\"token function\">GradientDescentStep</span><span class=\"token punctuation\">(</span>learningRate<span class=\"token punctuation\">,</span> currentParameters<span class=\"token punctuation\">,</span> currentFeatureVector<span class=\"token punctuation\">,</span> outcome<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span>  \n    <span class=\"token keyword\">let</span> biasedFeature <span class=\"token operator\">=</span> CreateBiasVector currentFeatureVector  \n    <span class=\"token keyword\">let</span> prediction <span class=\"token operator\">=</span> <span class=\"token function\">Predict</span><span class=\"token punctuation\">(</span>biasedFeature<span class=\"token punctuation\">,</span> currentParameters<span class=\"token punctuation\">)</span>  \n    <span class=\"token keyword\">let</span> loss <span class=\"token operator\">=</span> prediction <span class=\"token operator\">-</span> outcome  \n    <span class=\"token comment\">// do a gradient descent step into the gradient direction  </span>\n    DenseVector<span class=\"token punctuation\">.</span><span class=\"token function\">OfVector</span><span class=\"token punctuation\">(</span>currentParameters <span class=\"token operator\">-</span> <span class=\"token punctuation\">(</span>biasedFeature \\<span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span>loss \\<span class=\"token operator\">*</span> learningRate<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  </code></pre></div>\n<p>Yet another example for the type inference, but in this case I want to put your attention to the operator overloading. Yes in F# you can overload operators: As you can see in the parameter update, ”<em>currentParameters</em>” and ”<em>biasedFeature</em>” is a DenseVector, while loss and learningRate are floats (floats in F# are 64bit doubles, float32 is the “normal” float). The compiler has a small problem, because you can’t leave the brackets out, as it can’t determine the precedence correctly?</p>\n<p>In any case, the logic around that is pretty simple, very similar to a definition in maths.</p>\n<h4 id=\"testing-the-classifier-in-f\" style=\"position:relative;\"><a href=\"#testing-the-classifier-in-f\" aria-label=\"testing the classifier in f permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Testing the classifier in F#</h4>\n<p>In case the classifier is trained, we want to assess its learned weights. Usually, we use a hold-out test set to measure some metrics like accuracy or precision/recall, in this case I settled with sampling some new features from the random distribution we created the features with in the training stage. So how does that look like in F#?</p>\n<div class=\"gatsby-highlight\" data-language=\"fsharp\"><pre class=\"language-fsharp\"><code class=\"language-fsharp\"><span class=\"token keyword\">let</span> testSetSource <span class=\"token operator\">=</span> List<span class=\"token punctuation\">.</span>init testSetSize <span class=\"token punctuation\">(</span><span class=\"token keyword\">fun</span> <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span> <span class=\"token operator\">-></span> <span class=\"token function\">SampleNewFeature</span><span class=\"token punctuation\">(</span>dim<span class=\"token punctuation\">,</span> rnd<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  \n<span class=\"token keyword\">let</span> testSet <span class=\"token operator\">=</span>   \n      Seq<span class=\"token punctuation\">.</span>ofList testSetSource  \n      <span class=\"token operator\">|></span> Seq<span class=\"token punctuation\">.</span>map <span class=\"token punctuation\">(</span><span class=\"token keyword\">fun</span><span class=\"token punctuation\">(</span>feat<span class=\"token punctuation\">)</span> <span class=\"token operator\">-></span> feat<span class=\"token punctuation\">,</span> OnlineLogisticRegression<span class=\"token punctuation\">.</span><span class=\"token function\">Predict</span><span class=\"token punctuation\">(</span><span class=\"token function\">FeatureVector</span><span class=\"token punctuation\">(</span>feat<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> weights<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  \n      <span class=\"token operator\">|></span> Seq<span class=\"token punctuation\">.</span>map <span class=\"token punctuation\">(</span><span class=\"token keyword\">fun</span><span class=\"token punctuation\">(</span>feat<span class=\"token punctuation\">,</span> prediction<span class=\"token punctuation\">)</span> <span class=\"token operator\">-></span> feat<span class=\"token punctuation\">,</span> prediction<span class=\"token punctuation\">,</span> <span class=\"token function\">abs</span><span class=\"token punctuation\">(</span><span class=\"token function\">FeatureClass</span><span class=\"token punctuation\">(</span>feat<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> prediction<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span>  \n\n<span class=\"token keyword\">let</span> countCorrectPredictions <span class=\"token operator\">=</span> Seq<span class=\"token punctuation\">.</span>sumBy <span class=\"token punctuation\">(</span><span class=\"token keyword\">fun</span><span class=\"token punctuation\">(</span>feat<span class=\"token punctuation\">,</span> prediction<span class=\"token punctuation\">,</span> correct<span class=\"token punctuation\">)</span> <span class=\"token operator\">-></span> <span class=\"token keyword\">if</span> correct <span class=\"token keyword\">then</span> <span class=\"token number\">1</span> <span class=\"token keyword\">else</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>  \n<span class=\"token keyword\">let</span> numCorrect <span class=\"token operator\">=</span> countCorrectPredictions testSet  </code></pre></div>\n<p>As you can see, I have used the pipeline operator ( |> ) to chain operations together. First we create a new list containing the new and sampled test features, then we make it a sequence (which is a lazily evaluated structure that is similar to IEnumerable in C#).<br>\nInto that sequence, we map a three-tuple (the feature, the prediction and the learned weights) and then use another map stage to assess whether a classification was correct or not (threshold of the sigmoid here is 0.5). This in fact, is basically what’s currying about: we chain multiple operators together forming a new function.<br>\nIn the end, we sum the number of correct predictions by piping the sequences through the defined pipeline.<br>\nAll of this is lazily evaluated, the whole computation was just executed within the last line.</p>\n<h4 id=\"code\" style=\"position:relative;\"><a href=\"#code\" aria-label=\"code permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Code</h4>\n<p>The code can be found on GitHub, Apache 2.0 licensed: <a href=\"https://github.com/thomasjungblut/FSharpLogisticRegression\">https://github.com/thomasjungblut/FSharpLogisticRegression</a></p>\n<h4 id=\"result\" style=\"position:relative;\"><a href=\"#result\" aria-label=\"result permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Result</h4>\n<p>Executing the code in the GitHub repository yields to the following plot.\n<img src=\"https://raw.githubusercontent.com/thomasjungblut/FSharpLogisticRegression/master/separation.png\" alt=\"\"></p>\n<p>Thanks for reading.</p>","frontmatter":{"title":"Stochastic Logistic Regression in F#","date":"31st May 2014","description":null},"tableOfContents":"<ul>\n<li><a href=\"#learning-rule\">Learning Rule</a></li>\n<li><a href=\"#training-in-f\">Training in F#</a></li>\n<li><a href=\"#testing-the-classifier-in-f\">Testing the classifier in F#</a></li>\n<li><a href=\"#code\">Code</a></li>\n<li><a href=\"#result\">Result</a></li>\n</ul>","timeToRead":4},"previous":{"fields":{"slug":"/blogger/greatest-common-divisor-using-f/"},"frontmatter":{"title":"Greatest common divisor using F#"}},"next":{"fields":{"slug":"/blogger/minhashing-for-beginners/"},"frontmatter":{"title":"MinHashing for Beginners"}}},"pageContext":{"id":"21a9784d-ad71-5215-a660-37236303f25c","previousPostId":"8b9d3498-0e14-53c3-8831-909a7b48652d","nextPostId":"20c92f62-8d52-566b-8cff-74a7b830a248"}},"staticQueryHashes":["2270107033","2841359383"],"slicesMap":{}}