{"componentChunkName":"component---src-templates-blog-post-js","path":"/blogger/k-means-clustering-with-bsp-intuition/","result":{"data":{"site":{"siteMetadata":{"title":"Coding with Thomas"}},"markdownRemark":{"id":"58b5ef3f-6752-52fe-a344-0ecf6b1e0971","excerpt":"Hey all, I had a bit time to get my k-means clustering running with BSP and Apache Hama. I wanted to share this with you. Actually this is a sequel to a series…","html":"<p>Hey all,</p>\n<p>I had a bit time to get my k-means clustering running with BSP and Apache Hama. I wanted to share this with you.<br>\nActually this is a sequel to a series that I have announced long ago: <a href=\"http://codingwiththomas.blogspot.com/2011/05/series-k-means-clustering-mapreduce-bsp.html\">Series: K-Means Clustering (MapReduce | BSP)</a>.<br>\nYou may remember that I have already made a post about K-Means and MapReduce, now I want you to show that k-means clustering with BSP is much faster than the MapReduce one.<br>\nDon’t expect a benchmark in this post, but I will give you a real comparision a bit later once Apache Hama 0.4.0 rolls out.<br>\nSo this post is mainly about the algorithm itself and what my ideas were to make it running and scalable.<br>\nI’m going to make a next post which is containing more code and explain more clearly how it works. But code is still changing, so this will take a bit more time.</p>\n<p><strong>Quick note right at the beginning:</strong> As I mentioned it, I am currently developing with a Apache Hama 0.4.0 SNAPSHOT, since it hasn’t been released yet.</p>\n<p>Let’s step into it!</p>\n<p><strong>Model Classes</strong></p>\n<p>We need some kind of <em>Vector</em> and something that is going to represent our <em>Center</em>.</p>\n<p>These are very basic, actually it is just a wrapper object with an array of doubles and some convenience methods. A <em>Center</em> is just the same like a <em>Vector</em>, but it also adds some more methods to detect if it has converged or averaging two centers.</p>\n<p>You can have a look on Github at them if you’re interested.</p>\n<p><a href=\"https://github.com/thomasjungblut/thomasjungblut-common/blob/master/src/de/jungblut/clustering/model/Vector.java\">Vector.java</a></p>\n<p><a href=\"https://github.com/thomasjungblut/thomasjungblut-common/blob/master/src/de/jungblut/clustering/model/ClusterCenter.java\">ClusterCenter.java</a></p>\n<p><strong>Idea behind k-means with Apache Hama’s BSP</strong></p>\n<p>Before really showing you the algorithm in the source code, I’d like to tell you what my plan and intention was. </p>\n<p>In a typical clustering scenario you will have much much more points than centers/means. So n  >>  k (”>>” for much larger than), where n is our number of vectors and k is our number of centers. </p>\n<p>Since Apache Hama 0.4.0 will provide us with a new I/O system it makes it really easy to iterate over a chunk of the input on disk over and over again, we can use this fact and put all our centers into RAM.</p>\n<p>The trick in this case is that unlike in graph algorithms, we do not split the centers over the tasks, but every task holds all k-centers in memory. </p>\n<p>So each task gets a part of the big input file and every task has all centers. </p>\n<p>Now we can easily do our assignment step, we just iterate over all input vectors and measure the distance against every center. </p>\n<p>While iterating we find the nearest center for each of the n vectors. To save memory we are going to average our new center “on-the-fly”. Follow the <a href=\"http://en.wikipedia.org/wiki/Average#In_data_streams\">Average in data streams</a> article on Wikipedia, if you’re not familiar with it. </p>\n<p>At the end of the assignment step, we have in each task the “on-the-fly” computed average new centers. </p>\n<p>Now we are going to broadcast each of this computed averages to the other tasks.</p>\n<p>Then we are going to sync so all messages can be delivered.</p>\n<p>Afterwards we are iterating in each task through the messages and averaging all incoming centers if they belong to the same “old” mean. </p>\n<p>I know this is difficult to explain, but please consult this picture, it is about the exchange of the locally computed mean for two tasks.</p>\n<p><a href=\"http://3.bp.blogspot.com/-J9JImXsqb2I/TtuteUeY3ZI/AAAAAAAAAWw/XBenuFxet8A/s1600/messageExchange.png\"><img src=\"http://3.bp.blogspot.com/-J9JImXsqb2I/TtuteUeY3ZI/AAAAAAAAAWw/XBenuFxet8A/s320/messageExchange.png\" alt=\"\"></a></p>\n<p>Message exchange with mean calculation</p>\n<p>As you can see on this picture, we have two tasks which have calculated “their version” of a new mean. Since this isn’t the “global mean” we have to calculate a new mean that will be consistent across all the tasks and is still the correct mathematical mean.<br>\nWe apply the “Average on data streams” strategy. Each task is going to get the local computed averages from each other task and is reconstructing the global mean.</p>\n<p>Since this calculation is the same on every task, the means are still globally consistent across the tasks just with the cost of one global synchronization. Fine!<br>\nActually this is the whole intuition behind it. As the algorithm moves forward, this whole computation is running all over again until the centers converged = don’t change anymore.<br>\nThis is much faster than MapReduce, because you don’t have to submit a new job for a new computation step.<br>\nIn BSP the superstep is less costly than running a MapReduce job, therefore it is faster for this kind of tasks.</p>\n<p>When you plot the result, you come up with something that looks like this:</p>\n<p><a href=\"http://1.bp.blogspot.com/-kiZ1mNwiLvo/TtudNH4pGrI/AAAAAAAAAWo/ldCDDjFHTmY/s1600/kmeans_2.PNG\"><img src=\"http://1.bp.blogspot.com/-kiZ1mNwiLvo/TtudNH4pGrI/AAAAAAAAAWo/ldCDDjFHTmY/s320/kmeans_2.PNG\" alt=\"\"></a></p>\n<p>K-Means BSP Clustering with K=3</p>\n<p>In one of the upcoming posts, I’m going to explain you the code in detail.</p>\n<p>If you are interested in the code and can’t wait, you can have a look at it in my Github here:<br>\n<a href=\"https://github.com/apache/hama/tree/trunk/ml/src/main/java/org/apache/hama/ml/kmeans\">K-Means BSP Code</a></p>\n<p>The code will randomly create some vectos and assigns k initial centers to the first k-created records. You can run it via a main-method in your IDE or to your local-mode Hama cluster.</p>\n<p>See you!</p>","frontmatter":{"title":"k-Means Clustering with BSP (Intuition)","date":"10th December 2011","description":null},"tableOfContents":"","timeToRead":3},"previous":{"fields":{"slug":"/blogger/apache-hama-realtime-processing/"},"frontmatter":{"title":"Apache Hama realtime processing"}},"next":{"fields":{"slug":"/blogger/bsp-k-means-clustering-benchmark/"},"frontmatter":{"title":"BSP k-means Clustering Benchmark"}}},"pageContext":{"id":"58b5ef3f-6752-52fe-a344-0ecf6b1e0971","previousPostId":"36602d57-d098-56e8-bd0e-bcbafa49847c","nextPostId":"1e9cd2ae-f095-5348-b87e-bff15de60b9e"}},"staticQueryHashes":["2270107033","2841359383"],"slicesMap":{}}